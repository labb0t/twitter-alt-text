{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction and Takeaways\n",
    "This is a quick and dirty topic modeling analysis of the alt text in my corpus to check for any trends in what kinds of images are common on Twitter. Themes among the topics identified were:\n",
    "- images of animals (cats, dogs)\n",
    "- images of humans, especially selfies\n",
    "- images of relating to current events (in December 2020, these included Christmas and Covid)\n",
    "- images of text, including a lot of Spotify Wrapped screencaps\n",
    "\n",
    "An important flaw with this approach is that it can only tell us what kinds of images exist *among those that already have alt text*, which only represents a small portion of all Twitter images, and is likely a biased sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T23:46:08.346048Z",
     "start_time": "2020-12-17T23:46:08.315781Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/labbot/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# basics\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# files\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "#images\n",
    "from PIL import Image\n",
    "\n",
    "# nlp\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from SpacyPreprocessor import SpacyPreprocessor\n",
    "from TopicModelExploration import show_topics, show_top_docs\n",
    "\n",
    "from sklearn.decomposition import NMF, TruncatedSVD, LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T23:11:46.174606Z",
     "start_time": "2020-12-17T23:11:46.129687Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T23:40:43.035342Z",
     "start_time": "2020-12-17T23:40:43.022250Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('twitter_alt_text.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Prepoprcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lemmatize and remove numbers, symbols, POS with SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T23:11:41.056842Z",
     "start_time": "2020-12-17T23:11:40.098876Z"
    }
   },
   "outputs": [],
   "source": [
    "spacy_model = SpacyPreprocessor.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T23:11:46.055635Z",
     "start_time": "2020-12-17T23:11:41.059108Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4881it [00:04, 983.23it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessor = SpacyPreprocessor(spacy_model=spacy_model, lemmatize=True, remove_numbers=True, \n",
    "                                 remove_stopwords=False, remove_special=True, \n",
    "                                 pos_to_remove=['ADP','SYM','NUM','AUX'])\n",
    "df['spacy_pipe'] = preprocessor.preprocess_text_list(list(df['alt_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T23:11:46.101958Z",
     "start_time": "2020-12-17T23:11:46.057687Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>img_url</th>\n",
       "      <th>alt_text</th>\n",
       "      <th>media_type</th>\n",
       "      <th>spacy_pipe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1140807</th>\n",
       "      <td>1334658662565109761</td>\n",
       "      <td>2020-12-04 00:39:56</td>\n",
       "      <td>Jack is perfect. https://t.co/mePMDha4ot</td>\n",
       "      <td>https://t.co/mePMDha4ot</td>\n",
       "      <td>http://pbs.twimg.com/media/EoWo-ihXYAgvPxy.jpg</td>\n",
       "      <td>Jack the cat sleeping peacefully</td>\n",
       "      <td>photo</td>\n",
       "      <td>jack the cat sleep peacefully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213729</th>\n",
       "      <td>1335039542785662978</td>\n",
       "      <td>2020-12-05 01:53:25</td>\n",
       "      <td>Twitter, would it be legal for me to drive my ...</td>\n",
       "      <td>https://t.co/7Xj8xueKz7</td>\n",
       "      <td>http://pbs.twimg.com/media/EocDYsaXMAA6Ckm.jpg</td>\n",
       "      <td>Giant red bow on top of shiny black car with a...</td>\n",
       "      <td>photo</td>\n",
       "      <td>giant red bow top shiny black car a man a flan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486804</th>\n",
       "      <td>1334534352168894464</td>\n",
       "      <td>2020-12-03 16:25:58</td>\n",
       "      <td>@visakanv Black cardigan and a black scarf and...</td>\n",
       "      <td>https://t.co/AYLx8PryNA</td>\n",
       "      <td>http://pbs.twimg.com/media/EoU36kPWEAwLEft.jpg</td>\n",
       "      <td>Pink bag pack on green khaki jacket</td>\n",
       "      <td>photo</td>\n",
       "      <td>pink bag pack green khaki jacket</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id          created_at  \\\n",
       "1140807  1334658662565109761 2020-12-04 00:39:56   \n",
       "1213729  1335039542785662978 2020-12-05 01:53:25   \n",
       "486804   1334534352168894464 2020-12-03 16:25:58   \n",
       "\n",
       "                                                tweet_text  \\\n",
       "1140807           Jack is perfect. https://t.co/mePMDha4ot   \n",
       "1213729  Twitter, would it be legal for me to drive my ...   \n",
       "486804   @visakanv Black cardigan and a black scarf and...   \n",
       "\n",
       "                       tweet_url  \\\n",
       "1140807  https://t.co/mePMDha4ot   \n",
       "1213729  https://t.co/7Xj8xueKz7   \n",
       "486804   https://t.co/AYLx8PryNA   \n",
       "\n",
       "                                                img_url  \\\n",
       "1140807  http://pbs.twimg.com/media/EoWo-ihXYAgvPxy.jpg   \n",
       "1213729  http://pbs.twimg.com/media/EocDYsaXMAA6Ckm.jpg   \n",
       "486804   http://pbs.twimg.com/media/EoU36kPWEAwLEft.jpg   \n",
       "\n",
       "                                                  alt_text media_type  \\\n",
       "1140807                   Jack the cat sleeping peacefully      photo   \n",
       "1213729  Giant red bow on top of shiny black car with a...      photo   \n",
       "486804                 Pink bag pack on green khaki jacket      photo   \n",
       "\n",
       "                                                spacy_pipe  \n",
       "1140807                      jack the cat sleep peacefully  \n",
       "1213729  giant red bow top shiny black car a man a flan...  \n",
       "486804                    pink bag pack green khaki jacket  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check how that worked\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check for and remove super short documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T23:11:46.121471Z",
     "start_time": "2020-12-17T23:11:46.103716Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4881.000000\n",
       "mean       17.015775\n",
       "std        22.858222\n",
       "min         1.000000\n",
       "25%         5.000000\n",
       "50%        10.000000\n",
       "75%        20.000000\n",
       "max       291.000000\n",
       "Name: spacy_pipe_len, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['spacy_pipe_len'] = df['spacy_pipe'].str.split(\" \").str.len()\n",
    "df['spacy_pipe_len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T23:11:46.127154Z",
     "start_time": "2020-12-17T23:11:46.123102Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df['spacy_pipe_len'] >= 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Vectorizer and Topic Model\n",
    "I did minimal iteration with different pipelines here. A future step would be to set up a more robust pipeline and iterate through different vectorizers, models, and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T23:12:20.750523Z",
     "start_time": "2020-12-17T23:12:20.711052Z"
    }
   },
   "outputs": [],
   "source": [
    "# define corpus as the spacy-processed version of the data\n",
    "corpus = df['spacy_pipe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T23:12:22.673590Z",
     "start_time": "2020-12-17T23:12:22.636015Z"
    }
   },
   "outputs": [],
   "source": [
    "# define stopwords\n",
    "stop_words = spacy_model.Defaults.stop_words\n",
    "\n",
    "# add custom stopwords to stopwords list\n",
    "custom_stopwords = [\"pron\"]\n",
    "\n",
    "for s in custom_stopwords:\n",
    "    stop_words.add(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T23:12:18.604079Z",
     "start_time": "2020-12-17T23:12:18.563132Z"
    }
   },
   "outputs": [],
   "source": [
    "# define parameters for the vectorizer\n",
    "params = {\n",
    "    'stop_words':stop_words,\n",
    "    'min_df':10,\n",
    "    'ngram_range':(1, 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T23:12:24.264549Z",
     "start_time": "2020-12-17T23:12:24.112117Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/labbot/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3716, 743)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit vectorizer\n",
    "vectorizer = CountVectorizer(**params)\n",
    "doc_word_matrix = vectorizer.fit_transform(corpus)\n",
    "doc_word_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T23:12:26.077488Z",
     "start_time": "2020-12-17T23:12:25.938442Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "      <th>Topic_4</th>\n",
       "      <th>Topic_5</th>\n",
       "      <th>Topic_6</th>\n",
       "      <th>Topic_7</th>\n",
       "      <th>Topic_8</th>\n",
       "      <th>Topic_9</th>\n",
       "      <th>Topic_10</th>\n",
       "      <th>Topic_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AltText_0</th>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0413</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AltText_1</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2578</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AltText_2</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AltText_3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0320</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AltText_4</th>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Topic_0  Topic_1  Topic_2  Topic_3  Topic_4  Topic_5  Topic_6  \\\n",
       "AltText_0   0.0077   0.0050   0.0098   0.0413   0.0048   0.0056   0.0066   \n",
       "AltText_1   0.0000   0.2578   0.0000   0.0155   0.0054   0.0000   0.0000   \n",
       "AltText_2   0.0002   0.0010   0.0019   0.0050   0.0007   0.0000   0.0000   \n",
       "AltText_3   0.0000   0.0018   0.0026   0.0000   0.0000   0.0320   0.0000   \n",
       "AltText_4   0.0027   0.0044   0.0005   0.0006   0.0009   0.0000   0.0000   \n",
       "\n",
       "           Topic_7  Topic_8  Topic_9  Topic_10  Topic_11  \n",
       "AltText_0   0.0000   0.0267   0.0094    0.0018    0.0091  \n",
       "AltText_1   0.0000   0.0143   0.0044    0.0000    0.0143  \n",
       "AltText_2   0.0000   0.0003   0.0005    0.0000    0.0022  \n",
       "AltText_3   0.0000   0.0000   0.0033    0.0000    0.0009  \n",
       "AltText_4   0.0053   0.0072   0.0071    0.0125    0.0173  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and fit decomposition model\n",
    "nmf = NMF(n_components=12,random_state=7)\n",
    "\n",
    "# create the document-topic matrix\n",
    "doc_topic_matrix = nmf.fit_transform(doc_word_matrix)\n",
    "\n",
    "# create columns names\n",
    "topicnames = ['Topic_' + str(i) for i in range(nmf.n_components)]\n",
    "\n",
    "# index names\n",
    "docnames = ['AltText_' + str(i) for i in range(len(corpus))]\n",
    "\n",
    "# create a dataframe\n",
    "df_doc_topic = pd.DataFrame(np.round(doc_topic_matrix,4), columns=topicnames, index=docnames)\n",
    "\n",
    "df_doc_topic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore and Interpret Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T23:12:49.765877Z",
     "start_time": "2020-12-17T23:12:49.720263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['blue', 'red', 'wear', 'background', 'green', 'pink', 'dark',\n",
       "        'hair', 'light', 'yellow', 'purple', 'brown', 'eye', 'tree',\n",
       "        'grey'], dtype='<U18'),\n",
       " array(['text', 'image', 'read', 'image text', 'automatic',\n",
       "        'automatic image', 'text read', 'background', 'right', 'view',\n",
       "        'pay', 'page', 'book', 'set', 'item'], dtype='<U18'),\n",
       " array(['com', 'https', 'www', 'https www', 'instagram', 'twitter',\n",
       "        'follow', 'video', 'group', 'study', 'twitter com', 'office',\n",
       "        'join', 'comment', 'shot'], dtype='<U18'),\n",
       " array(['like', 'love', 'know', 'time', 'thing', 'number', 'people',\n",
       "        'good', 'feel', 'care', 'word', 'day', 'want', 'look like',\n",
       "        'small'], dtype='<U18'),\n",
       " array(['black', 'wear', 'wear black', 'hair', 'pink', 'shirt',\n",
       "        'black white', 'silver', 'tie', 'man', 'people', 'jacket',\n",
       "        'purple', 'dress', 'french'], dtype='<U18'),\n",
       " array(['screenshot', 'tweet', 'read', 'spotify', 'song', 'picture',\n",
       "        'wrap', 'spotify wrap', 'year', 'twitter', 'ep', 'listen',\n",
       "        'screenshot spotify', 'post', 'trend'], dtype='<U18'),\n",
       " array(['look', 'face', 'hold', 'panel', 'camera', 'right', 'eye', 'dog',\n",
       "        'pay', 'look like', 'close', 'th', 'mr', 'hair', 'profile'],\n",
       "       dtype='<U18'),\n",
       " array(['de', 'la', 'es', 'el', 'en', 'short', 'let', 'service', 'new',\n",
       "        'sign', 'article', 'total', 'city', 'co', 'school'], dtype='<U18'),\n",
       " array(['cat', 'photo', 'tree', 'christmas', 'christmas tree', 'sit',\n",
       "        'blanket', 'black cat', 'tabby', 'eye', 'picture', 'tabby cat',\n",
       "        'lay', 'paw', 'camera'], dtype='<U18'),\n",
       " array(['case', 'court', 'new', 'covid', 'order', 'december', 'return',\n",
       "        'line', 'result', 'high', 'day', 'november', 'test', 'trump',\n",
       "        'require'], dtype='<U18'),\n",
       " array(['white', 'black white', 'pink', 'brown', 'hold', 'woman', 'girl',\n",
       "        'hand', 'key', 'glass', 'face', 'hair', 'white woman', 'blanket',\n",
       "        'red'], dtype='<U18'),\n",
       " array(['use', 'system', 'form', 'public', 'new', 'include', 'font',\n",
       "        'plan', 'class', 'sound', 'space', 'collection', 'key', 'datum',\n",
       "        'file'], dtype='<U18')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_keywords = show_topics(vectorizer, nmf, 15)\n",
    "topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T23:14:34.526250Z",
     "start_time": "2020-12-17T23:14:34.479621Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "      <th>Topic_4</th>\n",
       "      <th>Topic_5</th>\n",
       "      <th>Topic_6</th>\n",
       "      <th>Topic_7</th>\n",
       "      <th>Topic_8</th>\n",
       "      <th>Topic_9</th>\n",
       "      <th>Topic_10</th>\n",
       "      <th>Topic_11</th>\n",
       "      <th>orig_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AltText_1917</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Page image from Opere del cardinale Pietro Bembo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AltText_23</th>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Guildy's head and tail stick out from behind t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Topic_0  Topic_1  Topic_2  Topic_3  Topic_4  Topic_5  Topic_6  \\\n",
       "AltText_1917   0.0000   0.1016    0.000   0.0000   0.0000   0.0000   0.0000   \n",
       "AltText_23     0.0097   0.0000    0.004   0.0019   0.0012   0.0008   0.0026   \n",
       "\n",
       "              Topic_7  Topic_8  Topic_9  Topic_10  Topic_11  \\\n",
       "AltText_1917      0.0   0.0000      0.0    0.0000       0.0   \n",
       "AltText_23        0.0   0.0157      0.0    0.0119       0.0   \n",
       "\n",
       "                                                  orig_comments  \n",
       "AltText_1917   Page image from Opere del cardinale Pietro Bembo  \n",
       "AltText_23    Guildy's head and tail stick out from behind t...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add original comments text back into doc_topic matrix\n",
    "df_doc_topic['orig_comments'] = df['alt_text'].values\n",
    "df_doc_topic.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T23:14:37.475723Z",
     "start_time": "2020-12-17T23:14:37.439255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['using System;\\nusing System.Collections.Generic;\\nusing System.ComponentModel;\\nusing System.Data;\\nusing System.Drawing;\\nusing System.Linq;\\nusing System.Text;\\nusing System.Threading.Tasks;\\nusing System.Windows.Forms;\\n\\nnamespace WindowsFormsApplication6\\n{\\n    public partial class Form1 : Form\\n    {\\n        private MyFont _font;\\n        public Form1()\\n        {\\n            InitializeComponent();\\n        }\\n\\n        priv...',\n",
       "       'Your next steps depend on the total of the Used column from the df -h command above.      If you’re using less space than your intended plan requires, you can move onto the next step without any further action.     If you’re using more space than your intended plan allows, you need to remove some files to free up some space before moving onto the next step. See the options for doing this in the Download Files from Your Linode guide.  Before resizing your Linode to a new plan, you need to resize the disk to match the storage volume of the new plan.',\n",
       "       'Benefits of vandhan bamboo bottle:\\nGreat sustainable eco friendly alternative to plastic.\\nno pesticides or fertilizer is used in growing a bamboo plant, the bottles are safe to store water and free from any kind of chemical.\\nThe process of manufacturing is completely organic, including the bamboo treating procedure. Instead of bleaching powder and other chemicals usually used to treat bamboo, we uses neem, turmeric and other herbal items to treat the product. We are insulating copper containers in them since copper is traditionally known to have many medicinal benefits. Vandhan Tripura bamboo bottles are far more superior than the products available in the market as they are properly treated and don’t store water directly on the bamboo surface.\\n',\n",
       "       \"\\t♥ Hands Free Function and Easy Setup----A10 Wireless Bluetooth Speaker connect easily with wireless Bluetooth device. Support TF card insert and USB input for non-Bluetooth devices. Instantly easy connect to your smart phone, PC, laptop, device by 3.5mm aux.\\n·\\t♥ Widely use. Whenever you're partying, walking out, camping, hiking, biking, enjoy a full-range stereo sound with a great volume.Can be Used with Laptops/Tablets/Mobile Phone/Mp4 Players.\\n·\\t♥ Long Battery Life and Rechargeable Battery----Fabulously perfect battery, take not long to charge but last for 6+ hrs . Play music without draining battery from your phone. With the rechargeable battery, you can carry it where I'm going.\\n·\\t♥ Louder Volume and Excellent Sound----Wonderful clear bass sound, this little speaker produces big sound, fit for outdoor camping as well. Bluetooth speaker Perfect for home, dorm room, kitchen, bathroom, car, parties, the sound fill all room. Plays up to 30 feet (10 meters) from any Bluetooth-enabled d\",\n",
       "       'How can I submit my ID verification documents – Blockchain. To make sure your personal information is submitted safely, documents must be sent through the Wallet’s ID verification portal. Personal documents will only be accepted if submitted using this method. For security reasons, we are unable to assist with verification requests sent through any other channel. This includes documents sent to us via email and support requests. If you’re asked to re-submit documents, an email will be sent to you with a secure upload link. Please use this secure upload link only; do not reply to the email with your attached documents. ',\n",
       "       'use autocxx::include_cpp;\\n\\ninclude_cpp! {\\n    #include \"url/origin.h\"\\n    generate!(\"url::Origin\")\\n    block!(\"url::Nonce\")\\n    // ... and 15 other block!()s\\n}\\n\\nuse ffi::*;\\n\\nfn main() {\\n    let o = url::Origin::CreateFromNormalizedTuple(\\n        make_string(\"https\"),\\n        make_string(\"google.com\"),\\n        443,\\n    );\\n    let serialized = o.Serialize1();\\n    println!(\\n        \"Hello, world! Origin is: {}\",\\n    ...',\n",
       "       'First, there is the lack of consistency. Housing courts across the country use a patchwork of services, including Webex, Zoom, BlueJeans, and others. In some places, like St. Louis, which has both city and county courts, the situation is split: one court uses Zoom and the other Webex. On top of this, some courts are fully virtual while others are hybrid, and others switch between virtual, hybrid, and in-person—sometimes during the same cases. This leads to many opportunities for confusion: Diamond, for example, says that she was required to appear in person for her second hearing, but the one after that is scheduled for Webex.)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_docs = show_top_docs(df_doc_topic, 'Topic_11',7)\n",
    "topic_docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "305.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
